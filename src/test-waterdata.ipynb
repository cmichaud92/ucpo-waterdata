{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893ab2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import logging\n",
    "from utils.fetch_data import fetch_nwis_data\n",
    "from utils.execute_sql_script import execute_sql_script\n",
    "from utils.transform_data import transform_nwis_iv_data, transform_nwis_site_data\n",
    "from utils.write_to_datalake import write_to_datalake\n",
    "import duckdb\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b84b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "usgs_sites = [\n",
    "    \"09152500\",   # Gunnison River Near Grand Junction, CO\n",
    "    \"09095500\",   # Colorado River Near Cameo, CO\n",
    "    \"09106150\",   # Colorado River Below Grand Valley Div NR Palisade, CO\n",
    "    \"09163500\",   # Colorado River Near Colorado-utah State Line\n",
    "    \"09306500\",   # White River Near Watson, Utah\n",
    "    \"09251000\",   # Yampa River Near Maybell, CO\n",
    "    \"09260050\",   # Yampa River at Deerlodge Park, CO\n",
    "    \"09260000\",   # Little Snake River Near Lily, CO\n",
    "    \"09261000\",   # Green River Near Jensen, UT\n",
    "    \"09315000\",   # Green River at Green River, UT\n",
    "    \"09302000\",   # Duchesne River Near Randlett, UT\n",
    "    \"09180000\",   # Dolores River Near Cisco, UT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c43794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "sites = usgs_sites\n",
    "parameter_codes = ['00060', '00010']\n",
    "start_date = '2022-01-01'\n",
    "end_date = (dt.date.today() - dt.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "service_code = 'iv'\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.resolve().parents[0]\n",
    "datalake_path = project_root / 'data' / 'hydrology_datalake'\n",
    "db_path = project_root / 'data' / 'hydrology.duckdb'\n",
    "# output_root = Path(__file__).resolve().parents[2] / 'hydrology_datalake' # ok for main.py\n",
    "# output_root = '/Volumes/T7_raw_I/waterdata_lake'\n",
    "# datalake_path = output_root / 'timeseries_iv'\n",
    "# ======================\n",
    "\n",
    "\n",
    "# Configure logging ------------------------------------------------\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "log_name = 'logs/' + dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + '.log'\n",
    "logging.basicConfig(filename=log_name,\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_str = ', '.join(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da56e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['agency_cd', 'site_no', 'station_nm', 'site_tp_cd', 'lat_va', 'long_va',\n",
       "       'dec_lat_va', 'dec_long_va', 'coord_meth_cd', 'coord_acy_cd',\n",
       "       'coord_datum_cd', 'dec_coord_datum_cd', 'district_cd', 'state_cd',\n",
       "       'county_cd', 'country_cd', 'land_net_ds', 'map_nm', 'map_scale_fc',\n",
       "       'alt_va', 'alt_meth_cd', 'alt_acy_va', 'alt_datum_cd', 'huc_cd',\n",
       "       'basin_cd', 'topo_cd', 'instruments_cd', 'construction_dt',\n",
       "       'inventory_dt', 'drain_area_va', 'contrib_drain_area_va', 'tz_cd',\n",
       "       'local_time_fg', 'reliability_cd', 'gw_file_cd', 'nat_aqfr_cd',\n",
       "       'aqfr_cd', 'aqfr_type_cd', 'well_depth_va', 'hole_depth_va',\n",
       "       'depth_src_cd', 'project_no'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sites_df = fetch_nwis_data(site=', '.join(sites), service_code='site')\n",
    "sites_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9749d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_cleaned = transform_nwis_site_data(sites_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ac04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [sites[0]]\n",
    "\n",
    "# output_root = notebook_dir.resolve().parents[0] / 'hydrology_datalake'\n",
    "print(f'Output root: {datalake_path}')\n",
    "print(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9f4b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck = execute_sql_script(project_root / 'src' / 'sql' / 'build_hydrology_duckdb.sql', duckdb_path=db_path)\n",
    "ck = execute_sql_script(project_root / 'src' / 'sql' / 'hydrology_datalake_views.sql', duckdb_path=db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f5aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(db_path)) as con:\n",
    "    con.register('sites_cleaned', sites_cleaned)\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO site (\n",
    "            site_code,\n",
    "            site_name,\n",
    "            agency_code,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            site_type,\n",
    "            hydro_area_name\n",
    "        )\n",
    "        SELECT\n",
    "            site_code,\n",
    "            site_name,\n",
    "            agency_code,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            site_type,\n",
    "            hydro_area_name\n",
    "        FROM sites_cleaned\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0857acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  site_code                                          site_name agency_code  \\\n",
      "0  09095500                     COLORADO RIVER NEAR CAMEO, CO.        USGS   \n",
      "1  09106150  COLO RIVER BELOW GRAND VALLEY DIV NR PALISADE, CO        USGS   \n",
      "2  09152500            GUNNISON RIVER NEAR GRAND JUNCTION, CO.        USGS   \n",
      "3  09163500       COLORADO RIVER NEAR COLORADO-UTAH STATE LINE        USGS   \n",
      "4  09180000                       DOLORES RIVER NEAR CISCO, UT        USGS   \n",
      "\n",
      "    latitude   longitude    site_type  hydro_area_name  \n",
      "0  39.239146 -108.266195  stream gage             <NA>  \n",
      "1  39.098592 -108.355086  stream gage             <NA>  \n",
      "2  38.983316 -108.450645  stream gage             <NA>  \n",
      "3  39.132760 -109.027055  stream gage             <NA>  \n",
      "4  38.797208 -109.195114  stream gage             <NA>  \n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect(str(db_path)) as con:\n",
    "    df = con.execute(\"\"\"\n",
    "            SELECT *\n",
    "            FROM sites_cleaned\n",
    "        \"\"\").fetch_df()\n",
    "    \n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62b98ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(db_path)) as con:\n",
    "    df = con.execute(\"\"\"\n",
    "                     SELECT *\n",
    "                     FROM vw_nwis_iv_local\n",
    "                     LIMIT 10\n",
    "                     \"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e66295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itterate through each site main function\n",
    "for site in sites:\n",
    "    print(f\"Processing site: {site}\")\n",
    "    #all_data = []\n",
    "\n",
    "    # Itterate through each parameter code\n",
    "    for pcode in parameter_codes:\n",
    "        \n",
    "        # Fetch data for the current site and parameter code from NWIS\n",
    "        df_raw = fetch_nwis_data(site, pcode, start_date, end_date, service_code)\n",
    "        if df_raw is None:\n",
    "            continue\n",
    "\n",
    "        # Clean and transform the data, standardizing column names and types\n",
    "        df_transformed = transform_nwis_iv_data(df_raw, site, pcode)\n",
    "        if df_transformed.empty:\n",
    "            continue\n",
    "\n",
    "        # Write the data to a parquet file\n",
    "        write_to_datalake(df_transformed, site, datalake_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT * \"\n",
    "    f\"FROM read_parquet('{output_root}\\\\timeseries_iv\\\\**\\\\*.parquet') \"\n",
    "    \"LIMIT 10;\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT * \"\n",
    "    f\"FROM '{output_root}\\\\timeseries_iv\\\\**\\\\*.parquet' \"\n",
    "    \"WHERE site = '09180000' AND year = 2023\"\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f588b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT \"\n",
    "    \"  site, \"\n",
    "    \"  date_trunc('day', datetime) AS day, \"\n",
    "    \"  parameter, \"\n",
    "    \"  AVG(value) AS daily_mean \"\n",
    "    f\"FROM read_parquet('{output_root}\\\\timeseries_iv\\\\**\\\\*.parquet') \"\n",
    "  #  \"WHERE parameter = '00060' \"\n",
    "  #  \" AND datetime >= '2023-01-01' \"\n",
    "    \"WHERE year = 2024 \"\n",
    "    \"GROUP BY site, date_trunc('day', datetime), parameter \"\n",
    "    \"ORDER BY site, day;\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351377a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT \"\n",
    "    \"  datetime AT TIME ZONE 'UTC' AT TIME ZONE 'America/Denver' AS local_time, * \"\n",
    "     f\"FROM read_parquet('{output_root}\\\\timeseries_iv\\\\**\\\\*.parquet') \"\n",
    "  #  \"WHERE parameter = '00060' \"\n",
    "  #  \" AND datetime >= '2023-01-01' \"\n",
    "    \"WHERE year = 2024 \"\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "print(Path.cwd())\n",
    "print(output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and execute the query\n",
    "with duckdb.connect() as con:\n",
    "    result = con.execute(query).fetchdf()\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(project_root / 'src' / 'sql' / 'hydrology_datalake_views.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "# Connect to DuckDB and execute the query\n",
    "with duckdb.connect() as con:\n",
    "    con.execute(sql_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e916f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"SELECT \"\n",
    "    \"  site, \"\n",
    "    \"  date_trunc('day', datetime_local) AS day_local, \"\n",
    "    \"  parameter, \"\n",
    "    \"  AVG(value) AS daily_mean \"\n",
    "    \"FROM vw_nwis_iv_local \"\n",
    "  #  \"WHERE parameter = '00060' \"\n",
    "  #  \" AND datetime >= '2023-01-01' \"\n",
    "    \"WHERE year = 2024 \"\n",
    "    \"GROUP BY site, date_trunc('day', datetime_local), parameter \"\n",
    "    \"ORDER BY site, day;\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and execute the query\n",
    "with duckdb.connect() as con:\n",
    "    result = con.execute(query).fetchdf()\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('/volumes/T7_raw_I/waterdata_lake/timeseries_iv/')\n",
    "    WHERE site = '09180000' AND year = 2023\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61de679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = duckdb.read_parquet(\n",
    "    f\"{output_root}/timeseries_iv/site=09180000/year=2023/data.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0745e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a623c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('data/data_lake/timeseries_iv/site=09152500/year=2022/data.parquet')\n",
    "df = table.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
